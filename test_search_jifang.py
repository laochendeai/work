#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¢å¼ºç‰ˆæœç´¢çˆ¬è™« - æœç´¢"æœºæˆ¿"
ä½¿ç”¨å¤šç§ç­–ç•¥é™ä½åçˆ¬é£é™©
"""
import sys
from pathlib import Path
import json
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))

from scraper.fetcher import PlaywrightFetcher
from scraper.ccgp_searcher_enhanced import CCGPSearcherSync
from scraper.ccgp_parser import CCGPAnnouncementParser


def test_enhanced_search_jifang():
    """
    æµ‹è¯•å¢å¼ºç‰ˆæœç´¢ - æœå…¨æ–‡"æœºæˆ¿"

    ä½¿ç”¨ç­–ç•¥ï¼š
    1. éšæœºUser-Agent
    2. æ¨¡æ‹Ÿäººå·¥æ“ä½œ
    3. å¢åŠ éšæœºå»¶è¿Ÿ
    4. å…ˆè®¿é—®é¦–é¡µå»ºç«‹ä¼šè¯
    """

    print("=" * 70)
    print("å…¬å…±èµ„æºäº¤æ˜“ç½‘æœç´¢ - å¢å¼ºç‰ˆæµ‹è¯•")
    print("=" * 70)

    # æœç´¢å‚æ•°
    keyword = "æœºæˆ¿"
    search_type = "fulltext"  # æœå…¨æ–‡
    category = "engineering"   # å·¥ç¨‹ç±»
    time_range = "1month"      # è¿‘1æœˆï¼ˆæ‰©å¤§æ—¶é—´èŒƒå›´æé«˜æˆåŠŸç‡ï¼‰
    max_pages = 2             # æµ‹è¯•åªçˆ¬2é¡µ

    print(f"\nğŸ” æœç´¢å‚æ•°:")
    print(f"  å…³é”®è¯: {keyword}")
    print(f"  æœç´¢ç±»å‹: {search_type}")
    print(f"  å“ç›®: {category}")
    print(f"  æ—¶é—´: {time_range}")
    print(f"  æœ€å¤§é¡µæ•°: {max_pages}")

    # åˆ›å»ºçˆ¬è™«
    fetcher = PlaywrightFetcher()

    try:
        fetcher.start()

        # ä½¿ç”¨å¢å¼ºç‰ˆæœç´¢å™¨
        searcher = CCGPSearcherSync(fetcher.page)

        print(f"\nå¼€å§‹æœç´¢...")

        # æ‰§è¡Œæœç´¢ï¼ˆä¼šä½¿ç”¨å¤šç§åè§„é¿ç­–ç•¥ï¼‰
        results = searcher.search(
            keyword=keyword,
            search_type=search_type,
            category=category,
            time_range=time_range,
            max_pages=max_pages,
        )

        print(f"\n{'=' * 70}")
        print(f"æœç´¢ç»“æœ: {len(results)} æ¡")
        print(f"{'=' * 70}")

        if not results:
            print("\nâš ï¸ æœªæ‰¾åˆ°æœç´¢ç»“æœ")
            print("\nå¯èƒ½çš„åŸå› :")
            print("  1. åçˆ¬é™åˆ¶ - å»ºè®®ç¨åå†è¯•")
            print("  2. æœç´¢æ¡ä»¶è¿‡ä¸¥ - å°è¯•æ‰©å¤§æ—¶é—´èŒƒå›´")
            print("  3. é€‰æ‹©å™¨å¤±æ•ˆ - ç½‘ç«™å¯èƒ½å·²æ›´æ–°")
            return

        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print(f"\næœç´¢ç»“æœ (å‰10æ¡):")
        print("-" * 70)

        for i, result in enumerate(results[:10], 1):
            print(f"{i}. {result.get('title', 'æœªçŸ¥æ ‡é¢˜')[:70]}")
            print(f"   URL: {result.get('url', '')}")

        if len(results) > 10:
            print(f"\n... è¿˜æœ‰ {len(results) - 10} æ¡ç»“æœ")

        # ===== çˆ¬å–è¯¦æƒ…é¡µ =====
        print(f"\n{'=' * 70}")
        print("å¼€å§‹çˆ¬å–è¯¦æƒ…é¡µ...")
        print(f"{'=' * 70}")

        parser = CCGPAnnouncementParser()
        detailed_results = []

        # åªçˆ¬å‰3ä¸ªç»“æœä½œä¸ºæ¼”ç¤º
        crawl_count = min(3, len(results))

        for i, result in enumerate(results[:crawl_count], 1):
            url = result.get('url', '')
            if not url:
                continue

            print(f"\n[{i}/{crawl_count}] {result.get('title', '')[:50]}")
            print(f"     URL: {url}")

            try:
                # è·å–è¯¦æƒ…é¡µ - å¢åŠ å»¶è¿Ÿé¿å…è§¦å‘é™åˆ¶
                import time
                time.sleep(3)  # æ¯ä¸ªè¯¦æƒ…é¡µé—´éš”3ç§’

                detail_html = fetcher.get_page(url)
                if not detail_html:
                    print("     âŒ è·å–è¯¦æƒ…é¡µå¤±è´¥")
                    continue

                # è§£æè¯¦æƒ…é¡µ
                parsed = parser.parse(detail_html, url)
                formatted = parser.format_for_storage(parsed)

                detailed_results.append(formatted)

                # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
                print(f"     âœ… é¡¹ç›®åç§°: {formatted.get('project_name', '')[:50]}")
                print(f"     ğŸ“ é‡‡è´­äºº: {formatted.get('buyer_name', '')[:30]}")
                print(f"     ğŸ† ä¸­æ ‡äºº: {formatted.get('supplier', '')[:30]}")
                print(f"     ğŸ’° ä¸­æ ‡é‡‘é¢: {formatted.get('bid_amount', '')[:30]}")

            except Exception as e:
                print(f"     âŒ å¤±è´¥: {e}")

        # ===== ä¿å­˜ç»“æœ =====
        print(f"\nä¿å­˜ç»“æœ...")

        output_file = Path("data/search_jifang_results.json")
        output_file.parent.mkdir(exist_ok=True)

        save_data = {
            'search_params': {
                'keyword': keyword,
                'search_type': search_type,
                'category': category,
                'time_range': time_range,
                'search_time': datetime.now().isoformat(),
            },
            'summary': {
                'total_results': len(results),
                'detailed_crawled': len(detailed_results),
            },
            'search_results': results,
            'detailed_results': detailed_results,
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        # ===== ç»Ÿè®¡ä¿¡æ¯ =====
        print(f"\n{'=' * 70}")
        print("ç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'=' * 70}")
        print(f"æœç´¢ç»“æœæ€»æ•°: {len(results)}")
        print(f"æˆåŠŸè§£æè¯¦æƒ…: {len(detailed_results)}")

        # ç»Ÿè®¡åŒ…å«"æœºæˆ¿"çš„é¡¹ç›®
        jifang_projects = [
            r for r in detailed_results
            if 'æœºæˆ¿' in r.get('project_name', '') or 'æœºæˆ¿' in r.get('title', '')
        ]

        print(f"åŒ…å«'æœºæˆ¿'çš„é¡¹ç›®: {len(jifang_projects)}")

        if jifang_projects:
            print(f"\nç›¸å…³é¡¹ç›®è¯¦æƒ…:")
            for r in jifang_projects:
                print(f"  - {r.get('project_name', '')[:50]}")
                print(f"    ä¸­æ ‡äºº: {r.get('supplier', '')}")

    finally:
        fetcher.stop()

    print(f"\n{'=' * 70}")
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print(f"{'=' * 70}")

    # ===== ä½¿ç”¨å»ºè®® =====
    print(f"\nğŸ’¡ é™ä½åçˆ¬é£é™©çš„å»ºè®®:")
    print(f"  1. æ¯æ¬¡æœç´¢é—´éš”è‡³å°‘5-10åˆ†é’Ÿ")
    print(f"  2. æ¯å¤©æœç´¢æ¬¡æ•°ä¸è¶…è¿‡3-5æ¬¡")
    print(f"  3. ä½¿ç”¨ä¸åŒçš„å…³é”®è¯å’Œæ¡ä»¶ç»„åˆ")
    print(f"  4. é¿å¼€é«˜å³°æ—¶æ®µï¼ˆå·¥ä½œæ—¶é—´ï¼‰")
    print(f"  5. è€ƒè™‘ä½¿ç”¨ä»£ç†IPæ± ")
    print(f"  6. ä¼˜å…ˆä½¿ç”¨åˆ—è¡¨é¡µçˆ¬å–æ–¹å¼")


if __name__ == '__main__':
    test_enhanced_search_jifang()
